{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Churn Prediction 'Die ZEIT' - Logistic Regression**\n",
    "\n",
    "#### **Pls install following packaged to your VE**\n",
    "\n",
    "**balancing:** <br/>\n",
    "conda install -c conda-forge imbalanced-learn <br/>\n",
    "**Xgboost classifierXgboost classifier:** <br/>\n",
    "conda install -c conda-forge xgboost <br/>\n",
    "\n",
    "### **Used Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Library for timing\n",
    "from time import time\n",
    "\n",
    "# Ignore warnings while plotting\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Feature Engineering & Selection modules\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# SUPERVISED LEARNING\n",
    "# Libraries for classification issues\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Libraries for classification and regression issues\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Libraries for splitting data, hyperparameter tuning & Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Librarie for data balancing\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Libraries for model evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve, f1_score\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, make_scorer, mean_squared_error\n",
    "\n",
    "# Display the whole content of the data frame\n",
    "pd.set_option('display.max_columns', None)   # Displays all columns\n",
    "pd.set_option('display.max_rows', None)      # Displays all rows\n",
    "\n",
    "# Define decimal places shown in the notebook\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chandrakanth/neuefischer/capstone-ZEIT-2020-ds/02_ml_model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/chandrakanth/neuefischer/capstone-ZEIT-2020-ds/00_data/f_chtr_churn_traintable_nf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data insight**\n",
    "#### **Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric and categorical features\n",
    "shape_init_rows = df.shape[0]\n",
    "shape_init_cols = df.shape[1]\n",
    "\n",
    "print('The shape of the data set: {0} rows, {1} columns'.format(shape_init_rows, shape_init_cols))\n",
    "print('   ')\n",
    "\n",
    "cont_f = df.select_dtypes(include=['float64', 'int64'])\n",
    "print('The number of numeric features: {0}'.format(len(cont_f.columns)))\n",
    "\n",
    "cat_f = df.select_dtypes(include=\"object\")\n",
    "print('The number of objectlike features: {0}'.format(len(cat_f.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations with target variable\n",
    "df.drop('churn', axis=1).corrwith(df.churn).sort_values().plot(kind='barh',figsize=(10, 50));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1 - Data Preprocessing for Modeling**\n",
    "### **Drop Irrelevant Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0',\n",
    "                 'auftrag_new_id',\n",
    "                 'kuendigungs_eingangs_datum',\n",
    "                 'avg_churn',\n",
    "                 'training_set'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Drop Redundant Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['ort',\n",
    "                 'plz_1',\n",
    "                 'plz_2'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dealing with Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['email_am_kunden'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric and categorical features\n",
    "shape_a_nan_rows = df.shape[0]\n",
    "shape_a_nan_cols = df.shape[1]\n",
    "\n",
    "\n",
    "print('The shape of the data set (after dealing with missing values): {0} rows, {1} columns'.format(shape_a_nan_rows, shape_a_nan_cols))\n",
    "print('By dropping the rows containing missing values, we removed {0} % of the rows \\n(compared to the inital data set).'\n",
    "      .format(round(((shape_init_rows-shape_a_nan_rows)/shape_init_rows)*100, ndigits=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric and categorical features\n",
    "print('The shape of the data set (after dropping columns and removing missing values): {0} rows, {1} columns'.format(df.shape[0], df.shape[1]))\n",
    "print('   ')\n",
    "\n",
    "cont_f = df.select_dtypes(include=['float64', 'int64'])\n",
    "print('The number of numeric features (after dropping): {0}'.format(len(cont_f.columns)))\n",
    "\n",
    "cat_f = df.select_dtypes(include=\"object\")\n",
    "print('The number of object features (after dropping): {0}'.format(len(cat_f.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dealing with DTypes and Dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info(verbose=1, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **DType Conversions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with categorical features and converting them -->> dtype = category\n",
    "category_features = ['kanal',\n",
    "                     'objekt_name',\n",
    "                     'aboform_name',\n",
    "                     'zahlung_rhythmus_name',\n",
    "                     'zahlung_weg_name',\n",
    "                     'land_iso_code',\n",
    "                     'anrede',\n",
    "                     'titel']\n",
    "\n",
    "df[category_features] = df[category_features].astype('category')\n",
    "\n",
    "# Removed temporarily: 'email_am_kunden'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns with dates -->> dtype = datetime\n",
    "df['liefer_beginn_evt'] = pd.to_datetime(df['liefer_beginn_evt'])\n",
    "df['abo_registrierung_min'] = pd.to_datetime(df['abo_registrierung_min'])\n",
    "df['nl_registrierung_min'] = pd.to_datetime(df['nl_registrierung_min'])\n",
    "df['date_x'] = pd.to_datetime(df['date_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new columns for datelike features (year & month)\n",
    "df['liefer_beginn_evt_year'] = df['liefer_beginn_evt'].dt.strftime('%Y')\n",
    "df['liefer_beginn_evt_month'] = df['liefer_beginn_evt'].dt.strftime('%m')\n",
    "\n",
    "df['abo_registrierung_min_year'] = df['abo_registrierung_min'].dt.strftime('%Y')\n",
    "df['abo_registrierung_min_month'] = df['abo_registrierung_min'].dt.strftime('%m')\n",
    "\n",
    "df['nl_registrierung_min_year'] = df['nl_registrierung_min'].dt.strftime('%Y')\n",
    "df['nl_registrierung_min_month'] = df['nl_registrierung_min'].dt.strftime('%m')\n",
    "\n",
    "df['date_x_year'] = df['date_x'].dt.strftime('%Y')\n",
    "df['date_x_month'] = df['date_x'].dt.strftime('%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping original datelike columns\n",
    "df.drop(columns=['liefer_beginn_evt',\n",
    "                 'abo_registrierung_min',\n",
    "                 'nl_registrierung_min',\n",
    "                 'date_x'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values for foreign countrys ('xx') with '000' and convert dtype\n",
    "df['plz_3'] = df['plz_3'].replace('xx', '000').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dummy Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List with varibales to be converted into dummies\n",
    "date_dum_features = ['liefer_beginn_evt_year',\n",
    "                 'liefer_beginn_evt_month',\n",
    "                 'abo_registrierung_min_year',\n",
    "                 'abo_registrierung_min_month',\n",
    "                 'nl_registrierung_min_year',\n",
    "                 'nl_registrierung_min_month',\n",
    "                 'date_x_year',\n",
    "                 'date_x_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies\n",
    "dummy_df1 = pd.get_dummies(df[category_features], drop_first=True)\n",
    "dummy_df2 = pd.get_dummies(df[date_dum_features], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns containing initial information for dummy columns\n",
    "df.drop(columns=category_features, inplace=True)\n",
    "df.drop(columns=date_dum_features, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creat Clean df for Modeling (Concatinate Dummies to df)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([df, dummy_df1,dummy_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_model.info(verbose=1, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2 - Modeling**\n",
    "### **Data Selection**\n",
    "+ y = Target variable -->>. ```churn```\n",
    "+ X = Predictors -->> ```remaining columns```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('churn',axis=1)\n",
    "y = df_model['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The target variable (y) has {0} rows.'.format(y.shape[0]))\n",
    "print('   ')\n",
    "print('The predictor variables (X) have {0} rows and {1} columns.'.format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test-Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data \n",
    "test_size = 0.3\n",
    "RSEED = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state = RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The test size is {} % of the preprocessed data set.'.format(test_size*100))\n",
    "print('   ')\n",
    "print('The train set has {0} rows.'.format(X_train.shape[0]))\n",
    "print('   ')\n",
    "print('The test set has {0} rows.'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function for: Predicting the Target Value ('churn') & Evaluating the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function for prediction\n",
    "def predict(X_train, X_test, y_train, y_test, model):\n",
    "    \n",
    "    '''\n",
    "    inputs:\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "       - model: the model algorithm to be trained and predicted on\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Fit the learner to the training data \n",
    "    start = time() # Get start time\n",
    "    model = model.fit(X_train ,y_train)\n",
    "    end = time() # Get end time\n",
    "      \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # Get the predictions on the test set and training set,\n",
    "    start = time() # Get start time\n",
    "    predictions_test = model.predict(X_test)\n",
    "    predictions_train = model.predict(X_train)\n",
    "    predictions_test_prob = model.predict_proba(X_test)\n",
    "    predictions_train_prob = model.predict_proba(X_train)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    '''\n",
    "    Evaluation through different parameters\n",
    "    '''\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "    \n",
    "    # Compute accuracy on the train set\n",
    "    results['acc_train'] = accuracy_score(y_train,predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    \n",
    "    # Compute Precision_score on the train set\n",
    "    results['Precision_train'] = precision_score(y_train, predictions_train)\n",
    "    \n",
    "    # Compute Precision_score on the test set\n",
    "    results['Precision_test'] = precision_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute Recall_score on the train set\n",
    "    results['Recall_train'] = recall_score(y_train ,predictions_train)\n",
    "    \n",
    "    # Compute Recall_score on the test set\n",
    "    results['Recall_test'] = recall_score(y_test, predictions_test)\n",
    "    \n",
    "    # Final results\n",
    "    print (\"{} trained .\".format(model.__class__.__name__))\n",
    "    \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the two models\n",
    "model_NB = GaussianNB(var_smoothing=1e-09)\n",
    "\n",
    "model_LG =  LogisticRegression()\n",
    "\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "\n",
    "model_RF = RandomForestClassifier(n_estimators=500, min_samples_split = 2, \n",
    "                               max_leaf_nodes = 50, max_depth = 25, \n",
    "                               bootstrap = True, max_features = 'auto',   \n",
    "                               n_jobs=-1, verbose = 1, random_state=RSEED)\n",
    "\n",
    "model_XGB = XGBClassifier(n_estimators = 200, gamma = 100, \n",
    "                      learning_rate = 0.01, max_depth = 12, booster = 'gbtree',\n",
    "                      scale_pos_weight = 1.5, objective='binary:logistic')\n",
    "\n",
    "\n",
    "results = {}\n",
    "for model in [model_NB, model_LG, model_KNN, model_RF, model_XGB]:\n",
    "    model_name = model.__class__.__name__\n",
    "    results[model_name] = {}\n",
    "    results[model_name] = \\\n",
    "    predict(X_train, X_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the results of predictions\n",
    "for i in results.items():\n",
    "    print (i[0])\n",
    "    display(pd.DataFrame.from_dict(i[1], orient='index').rename(columns={0:'uncleaned data'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "#print(results['KNeighborsClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap\n",
    "#        conf_mat = pd.crosstab(np.ravel(y_train), np.ravel(y_train_pred),\n",
    "#                               colnames=[\"Predicted\"], rownames=[\"Actual\"])\n",
    "    \n",
    "#        sns.heatmap(conf_mat/np.sum(conf_mat), annot=True, cmap=\"Blues\", fmt=\".2%\")\n",
    "#        plt.show()\n",
    "#        plt.close()\n",
    "\n",
    "######################\n",
    "\n",
    "#print(\"\\nResults on test data:\")\n",
    "#print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
